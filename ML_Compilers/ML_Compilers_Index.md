# ML Compilers Knowledge Map

This is a comprehensive overview of Machine Learning Compilers, their components, and related technologies.

## Core Areas
- [[ML Compilers Introduction]] - Basic concepts and overview
- [[Tensor Programming]] - Languages and frameworks for tensor computation
- [[ML Compiler Optimization]] - Optimization techniques and strategies
- [[Advanced ML Topics]] - Parallel computing and custom hardware
- [[ML Compiler Tools]] - Practical applications and development tools
- [[ML Compiler Resources]] - Research papers, courses, and community

## Learning Path
1. Start with [[ML Compilers Introduction]] for basic concepts
2. Explore [[Tensor Programming]] and [[Tensor Languages]] for fundamental frameworks
3. Learn optimization through [[ML Compiler Optimization]] and [[Model Optimization Strategies]]
4. Study hardware adaptation with [[Hardware-Aware Compilation]]
5. Advance to [[Parallel Computing ML]] and [[Custom Hardware ML]] for specialized concepts
6. Get hands-on with [[ML Compiler Tools]] and [[Compiler Construction Projects]]
7. Stay updated through [[ML Compiler Resources]] and [[Research Papers]]

## Key Topics by Area

### Introduction
- Role of compilers in ML workflows
- Performance optimization principles
- [[ML Fundamental Concepts]] - Mathematical foundations

### Tensor Programming
- [[Tensor Languages]] - DSLs and programming abstractions
- [[ML Compiler Frameworks]] - Major compiler stacks
- [[MLIR Framework]] - Multi-level IR infrastructure
- [[TensorFlow XLA]] - TensorFlow's compiler

### Optimization
- [[Model Optimization Strategies]] - Graph and tensor optimizations
- [[Hardware-Aware Compilation]] - Target-specific optimizations
- [[Operator Fusion Techniques]] - Operation combining strategies
- [[Auto-Tuning Systems]] - Automated performance optimization

### Hardware and Parallelism
- [[Parallel Computing ML]] - Parallel processing techniques
- [[Custom Hardware ML]] - Specialized accelerators
- [[GPU Architecture]] - GPU optimization specifics
- [[TPU Architecture]] - TPU design and compilation
- [[Systolic Arrays]] - Foundational architecture for TPUs and ML accelerators

### Tools and Applications
- [[Compiler Construction Projects]] - Hands-on development
- [[Industry Tools]] - Production-ready tools
- [[ML Performance Benchmarking]] - Evaluation methodologies
- [[MLIR Development Tools]] - MLIR-specific utilities

### Resources
- [[Research Papers]] - Important academic publications
- [[Learning Resources]] - Courses and tutorials
- [[Community Forums]] - Discussion and support

## Additional Topics
- [[Quantization Techniques]] - Precision reduction methods
- [[Layout Transformations]] - Memory layout optimizations
- [[FPGA Acceleration]] - FPGA-specific considerations
- [[Compiler Pipeline Design]] - End-to-end compilation process

---
Tags: #ml-compilers #index #learning-path 